{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "a = glob('/mnt/tuannb/Crawl_data/Name_domain/*/*.json')\n",
    "cc = 0\n",
    "for item in a:\n",
    "    dt = json.load(open(item, 'r'))\n",
    "    for itm in dt:\n",
    "        for im in itm['QA']: \n",
    "            if len(im['question']) != 0 and len(im['context']) != 0 and len(im['answer']) != 0:\n",
    "                cc += 1\n",
    "            # cc += 1\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://thuvienphapluat.vn/phap-luat/trach-nhiem-tra-no-trong-truong-hop-doanh-nghiep-co-khoan-thua-lo-lon-hon-von-dieu-le-cong-ty-co-ph-524378-10544.html'\n",
    "\n",
    "get_sample(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://thuvienphapluat.vn/phap-luat/tieu-chuan-chuc-danh-pho-truong-phong-giao-duc-va-dao-tao-thuoc-uy-ban-nhan-dan-huyen-quy-dinh-nhu--376032-36290.html?rel=goi-y-cung-tag'\n",
    "def get_all(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        table = soup.find('body').find('div', attrs={'class' : 'tvpl-main container pt-3 pb-3 wap-page-detail'})\n",
    "        return table\n",
    "    pass\n",
    "\n",
    "def get_categories(table):\n",
    "    list_categires = table.find_all('div', attrs={'class' : 'row'})[1].find('div', attrs={'class' : \"col-md-9\"}) \\\n",
    "                          .find('article').find('div', attrs={'class' : 'row'}) \\\n",
    "                          .find('section', attrs={'class' : 'col-md-3'}) \\\n",
    "                          .find_all('section', attrs={'class' : 'news-box-keyword mb-3'}) \n",
    "    list_cate = []\n",
    "    for item in list_categires:\n",
    "        list_cate.append(item.find('header', attrs={'class' : 'fs-6 fw-bold p-2 m-0'}).find('a').text)\n",
    "    return list_cate\n",
    "\n",
    "                \n",
    "get_categories(get_all(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "a = glob('/mnt/tuannb/Crawl_data/Split Phap Luat/*/data_domain.json')\n",
    "list_folder = json.load(open('/mnt/tuannb/Crawl_data/Split Phap Luat/doanh nghiep/data_domain.json', 'r'))\n",
    "\n",
    "\n",
    "total_data = []\n",
    "q = 0\n",
    "\n",
    "for item in tqdm(a):\n",
    "    with open(item, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(item.split('/')[-2])\n",
    "    new_data, leng = get_data_process_and_combine(data)\n",
    "    total_data += new_data\n",
    "    q += leng\n",
    "    with open('/'.join(item.split('/')[:-1]) + '/combine_data.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_data, f, ensure_ascii=False)\n",
    "print('total: ' + str(q))\n",
    "\n",
    "\n",
    "a = glob('/mnt/tuannb/Crawl_data/Split Phap Luat/*/combine_data.json')\n",
    "\n",
    "count_length = [0 for _ in range(10000)]\n",
    "for item in a:\n",
    "    with open(item, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for sample in tqdm(data):\n",
    "        for item in sample['samples']:\n",
    "            count_length[len(item['context'].split(' '))] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_index = -1  # Đặt giá trị ban đầu là -1 để xác định rằng chưa tìm thấy phần tử lớn nhất\n",
    "total = 0\n",
    "plt.plot(count_length[:1000])\n",
    "for num in count_length[:1001]:\n",
    "    total += num\n",
    "\n",
    "# Tính trung bình\n",
    "average = total / 1000\n",
    "\n",
    "# Đặt nhãn cho trục x và trục y (tuỳ chọn)\n",
    "plt.xlabel('Length Context')\n",
    "plt.ylabel('Count Context')\n",
    "\n",
    "# Đặt tiêu đề cho biểu đồ (tuỳ chọn)\n",
    "plt.title('Mean: ' + str(average))\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_index = -1  # Đặt giá trị ban đầu là -1 để xác định rằng chưa tìm thấy phần tử lớn nhất\n",
    "total = 0\n",
    "count = 0\n",
    "plt.plot(count_length[:1000])\n",
    "for idx, num in enumerate(count_length[:1001]):\n",
    "    total += idx*num\n",
    "    count += num\n",
    "    \n",
    "# Tính trung bình\n",
    "average = total / count\n",
    "\n",
    "# Đặt nhãn cho trục x và trục y (tuỳ chọn)\n",
    "plt.xlabel('Length Context')\n",
    "plt.ylabel('Count Context')\n",
    "\n",
    "# Đặt tiêu đề cho biểu đồ (tuỳ chọn)\n",
    "plt.title('Mean: ' + str(average))\n",
    "\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for item in total_data:\n",
    "    for itm in item['samples']:\n",
    "        new_data.append(itm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "remove_answer = open('/mnt/tuannb/Crawl_data/Remove/remove_answer.txt', 'r').read().split('\\n')\n",
    "\n",
    "for item in tqdm(new_data):\n",
    "    flag = True\n",
    "    for remove in remove_answer:\n",
    "        if remove in item['answer']:\n",
    "            flag = False\n",
    "            break\n",
    "        \n",
    "    if flag == True:\n",
    "        data.append(item)\n",
    "        \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_first_letter(input_string):\n",
    "    \"\"\"Capitalizes the first letter of a string.\"\"\"\n",
    "    if not input_string:\n",
    "        return input_string\n",
    "    \n",
    "    return input_string[0].upper() + input_string[1:]\n",
    "\n",
    "import re\n",
    "\n",
    "def format_text_advanced(text):\n",
    "    \"\"\"\n",
    "    Format the entire text by removing leading/trailing whitespaces and special characters,\n",
    "    capitalize the first letter of each sentence, handle line breaks after commas, and remove line breaks before commas.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted text.\n",
    "    \"\"\"\n",
    "    # Remove line breaks before commas\n",
    "    text = re.sub(r'\\n\\s*,', ',', text)\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    # Format each sentence\n",
    "    formatted_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        formatted_sentence = re.sub(r'^[^\\w]+', '', sentence.strip()).capitalize()\n",
    "\n",
    "        # Check if the current sentence ends with a period and the next sentence starts with a comma\n",
    "        if i < len(sentences) - 1 and sentence.endswith('.') and sentences[i + 1].startswith(','):\n",
    "            formatted_sentence += ','\n",
    "\n",
    "        formatted_sentences.append(formatted_sentence)\n",
    "\n",
    "    # Join the formatted sentences into formatted text\n",
    "    formatted_text = ' '.join(formatted_sentences)\n",
    "    return formatted_text\n",
    "\n",
    "\n",
    "def all_format(text):\n",
    "    return capitalize_first_letter(capitalize_first_letter((text.removeprefix('\\n').removeprefix(',').strip().removeprefix(',').strip().replace('\\n,', ','))))\n",
    "\n",
    "\n",
    "dt = []\n",
    "\n",
    "for item in tqdm(data):\n",
    "    dt.append({\n",
    "        'question': all_format(item['question']),\n",
    "        'context': all_format(item['context']),\n",
    "        'answer': all_format(item['answer']).strip(),\n",
    "        'reference': item['reference'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TerminalColors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    OKPINK = \"\\033[95m\"\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'  # Kết thúc màu sắc\n",
    "    \n",
    "\n",
    "vl = []\n",
    "for itm in dt:\n",
    "    if 'Quảng cáo phân bón được quy định như thế nào?' in itm['question'] or 'Tiêu chuẩn để chăn nuôi nông hộ là gì?' in itm['question']:\n",
    "        # print(TerminalColors.OKGREEN + itm['question'] + \"\\n\" + TerminalColors.ENDC)\n",
    "        # print(TerminalColors.WARNING + itm['answer']  + '\\n' + TerminalColors.ENDC)\n",
    "        # print('---'*40)\n",
    "        continue\n",
    "    else:\n",
    "        vl.append(itm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(vl, open('/mnt/tuannb/Data/Law_QA_4_12/law_qa.json', 'w'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pseudo = []\n",
    "\n",
    "for _ in range(40000):\n",
    "    a = random.randint(0, 170000)\n",
    "    context = ''\n",
    "    while True:\n",
    "        b = random.randint(0, 170000)\n",
    "        if vl[a]['question'] != vl['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 94.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53977"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "split_domain = json.load(open('/mnt/tuannb/Data/Law_QA_4_12/split_domain.json', 'r'))\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "pseudo = []\n",
    "\n",
    "list_domain = list(split_domain.keys())\n",
    "\n",
    "for domain in tqdm(list_domain):\n",
    "    for _ in range(2000):\n",
    "        length = len(split_domain[domain])\n",
    "        first = random.randint(0, length - 2)\n",
    "        second = random.randint(0, length - 2)\n",
    "        if split_domain[domain][first]['answer'] != split_domain[domain][second]['answer']:\n",
    "            pseudo.append({\n",
    "                'question': split_domain[domain][first]['question'],\n",
    "                'context': split_domain[domain][second]['context'],\n",
    "                'answer': 'Không có thông tin',\n",
    "                'reference': split_domain[domain][first]['reference'],\n",
    "                'domain': split_domain[domain][first]['domain']\n",
    "            })\n",
    "\n",
    "len(pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 2126.89it/s]\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "\n",
    "data = []\n",
    "for domain in tqdm(list_domain):\n",
    "    for item in split_domain[domain]:\n",
    "        data.append(item)\n",
    "        \n",
    "random.shuffle(pseudo)\n",
    "random.shuffle(data)\n",
    "\n",
    "train = []\n",
    "for item in data[:160000]:\n",
    "    train.append(item)\n",
    "    \n",
    "for item in pseudo[:40000]:\n",
    "    train.append(item)\n",
    "\n",
    "test = data[160000:]\n",
    "pseudo_test = pseudo[40000:]\n",
    "random.shuffle(train)\n",
    "# json.dump(train, open('/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/train.json', 'w'), ensure_ascii=False)\n",
    "# json.dump(test, open('/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/test.json', 'w'), ensure_ascii=False)\n",
    "# json.dump(pseudo_test, open('/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/pseudo_test.json', 'w'), ensure_ascii=False)\n",
    "    \n",
    "# json.dump(pseudo, open('/mnt/tuannb/Data/Law_QA_4_12/pseudo.json', 'w'), ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_jsonl(data, path):\n",
    "    with open(path, \"w\", encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")   \n",
    "    pass\n",
    "\n",
    "def load_jsonl(path_file):\n",
    "    list_data = []\n",
    "    with open(path_file, 'r') as file:\n",
    "        for line in file:\n",
    "            list_data.append(json.loads(line))\n",
    "    return list_data\n",
    "\n",
    "# save_jsonl(train, path='/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/train.jsonl')\n",
    "\n",
    "# save_jsonl(test, path='/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/test.jsonl')\n",
    "\n",
    "# save_jsonl(pseudo_test, path='/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/pseudo_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_jsonl('/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/train_v2.jsonl')\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Công chức khi sử dụng hồ sơ điện tử cá nhân công chức trên Hệ thống thông tin công chức viên chức Bộ Tài nguyên và Môi trường cần tuân theo những quy định gì?',\n",
       " 'context': 'Căn cứ tại khoản 1 Điều 9 Quy chế quản lý, khai thác Hệ thống thông tin công chức, viên chức Bộ Tài nguyên và Môi trường ban hành kèm theo Quyết định 2715/QĐ-BTNMT năm 2016, có quy định về nghiên cứu, khai thác và sử dụng thông tin hồ sơ điện tử cá nhân như sau:\\nNghiên cứu, khai thác và sử dụng thông tin hồ sơ điện tử cá nhân\\n1. Đối tượng được nghiên cứu, sử dụng và khai thác hồ sơ điện tử cá nhân:\\na) Đơn vị quản lý, sử dụng công chức, viên chức được nghiên cứu, khai thác và sử dụng thông tin hồ sơ điện tử công chức, viên chức trên hệ thống để phục vụ yêu cầu công tác.\\nb) Công chức, viên chức được sử dụng toàn bộ thông tin hồ sơ điện tử cá nhân của mình nhưng không được phép sửa chữa, thêm bớt nội dung thông tin hồ sơ điện tử cá nhân của mình.\\n… \\nCăn cứ tại khoản 2 Điều 9 Quy chế quản lý, khai thác Hệ thống thông tin công chức, viên chức Bộ Tài nguyên và Môi trường ban hành kèm theo Quyết định 2715/QĐ-BTNMT năm 2016, có quy định về nghiên cứu, khai thác và sử dụng thông tin hồ sơ điện tử cá nhân như sau:\\nNghiên cứu, khai thác và sử dụng thông tin hồ sơ điện tử cá nhân\\n…\\n2. Các quy định khi nghiên cứu, khai thác và sử dụng hồ sơ điện tử cá nhân:\\na) Công chức, viên chức được giao quản lý, sử dụng hệ thống của đơn vị, tổ chức được cấp quyền cập nhật, chỉnh sửa, khai thác các nội dung liên quan đến nhiệm vụ, công việc được giao.\\nb) Lãnh đạo đơn vị và công chức, viên chức được giao quản lý, sử dụng hệ thống chịu trách nhiệm bảo mật thông tin và chỉ sử dụng thông tin phục vụ công tác quản lý hành chính nhà nước của đơn vị. \\nCăn cứ tại điểm a khoản 1 Điều 11 Quy chế quản lý, khai thác Hệ thống thông tin công chức, viên chức Bộ Tài nguyên và Môi trường ban hành kèm theo Quyết định 2715/QĐ-BTNMT năm 2016, có quy định về thẩm quyền và trách nhiệm của Vụ Tổ chức cán bộ trực thuộc Bộ\\nThẩm quyền và trách nhiệm của Vụ Tổ chức cán bộ trực thuộc Bộ\\n1. Thẩm quyền của Vụ Tổ chức cán bộ\\na) Giúp Bộ trưởng quản lý, khai thác, sử dụng thông tin hồ sơ điện tử cá nhân trên hệ thống, bao gồm:\\n- Lãnh đạo Bộ;\\n- Công chức của các Vụ, Văn phòng Bộ, Thanh tra Bộ;\\n- Lãnh đạo, Kế toán trưởng, phụ trách kế toán các đơn vị trực thuộc Bộ;\\n- Chủ tịch Hội đồng thành viên, thành viên Hội đồng thành viên, Chủ tịch công ty, Tổng giám đốc, Phó tổng giám đốc, Kiểm soát viên, Kế toán trưởng các doanh nghiệp Nhà nước trực thuộc Bộ; Giám đốc, Phó giám đốc, Trưởng ban kiểm soát, Kiểm soát viên, Kế toán trưởng Quỹ Bảo vệ môi trường Việt Nam;\\n- Lãnh đạo các tổ chức trực thuộc Tổng cục, Cục, Trung tâm Khí tượng Thủy văn quốc gia; lãnh đạo các liên đoàn trực thuộc Trung tâm Quy hoạch và Điều tra tài nguyên nước quốc gia; lãnh đạo các tổ chức sự nghiệp, Chi cục và người đứng đầu các tổ chức còn lại trực thuộc Cục trực thuộc Bộ;\\n- Người đứng đầu các tổ chức trực thuộc đơn vị sự nghiệp trực thuộc Bộ;\\n- Người đứng đầu các Chi cục trực thuộc Cục trực thuộc Tổng cục trực thuộc Bộ;\\n- Người đứng đầu các tổ chức trực thuộc Văn phòng Hội đồng đánh giá trữ lượng khoáng sản quốc gia, Văn phòng Ban Chỉ đạo 33, Văn phòng Thường trực Ủy ban sông Mê Công Việt Nam;\\n- Hồ sơ công chức từ chuyên viên chính và tương đương trở lên;\\n- Hồ sơ dự tuyển thi công chức vào các đơn vị trực thuộc Bộ.\\nb) Khai thác, sử dụng thông tin hồ sơ điện tử cá nhân của tất cả công chức, viên chức thuộc Bộ để phục vụ công tác quản lý.\\n…',\n",
       " 'answer': 'Công chức được giao sử dụng hồ sơ điện tử cá nhân công chức trên Hệ thống thông tin công chức viên chức Bộ Tài nguyên và Môi trường của đơn vị, tổ chức được cấp quyền cập nhật, chỉnh sửa, khai thác các nội dung liên quan đến nhiệm vụ, công việc được giao.\\nCông chức được giao quản lý, sử dụng hệ thống chịu trách nhiệm bảo mật thông tin và chỉ sử dụng thông tin phục vụ công tác quản lý hành chính nhà nước của đơn vị',\n",
       " 'reference': ['https://thuvienphapluat.vn/van-ban/Bo-may-hanh-chinh/Quyet-dinh-2715-QD-BTNMT-Quy-che-quan-ly-khai-thac-He-thong-thong-tin-cong-chuc-vien-chuc-429586.aspx?anchor=dieu_9'],\n",
       " 'domain': ['Bộ máy hành chính']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:52<00:00, 1776.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = load_dataset('json', data_files='/mnt/tuannb/Data/Law_QA_4_12/Train_Version_1/train_full.jsonl')\n",
    "count = 0\n",
    "\n",
    "for item in tqdm(train['train']):\n",
    "    if len(item['input_ids']) > 1024:\n",
    "        count += 1\n",
    "        \n",
    "count\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuannb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
