{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7929592,"sourceType":"datasetVersion","datasetId":4660677},{"sourceId":7929617,"sourceType":"datasetVersion","datasetId":4660696},{"sourceId":8016689,"sourceType":"datasetVersion","datasetId":4723295},{"sourceId":8307749,"sourceType":"datasetVersion","datasetId":4934677}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:26:57.266340Z","iopub.execute_input":"2024-05-05T15:26:57.266980Z","iopub.status.idle":"2024-05-05T15:27:10.485874Z","shell.execute_reply.started":"2024-05-05T15:26:57.266947Z","shell.execute_reply":"2024-05-05T15:27:10.484750Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport rouge\nfrom transformers import AutoConfig, AutoTokenizer, MBartForConditionalGeneration\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n#from utils.preprocess import *\nfrom rouge import Rouge     \nimport wandb\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:10.487881Z","iopub.execute_input":"2024-05-05T15:27:10.488178Z","iopub.status.idle":"2024-05-05T15:27:30.323113Z","shell.execute_reply.started":"2024-05-05T15:27:10.488153Z","shell.execute_reply":"2024-05-05T15:27:30.322338Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-05 15:27:20.357058: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-05 15:27:20.357158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-05 15:27:20.485988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('vinai/bartpho-word-base')\nmodel = MBartForConditionalGeneration.from_pretrained('vinai/bartpho-word-base')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:30.324091Z","iopub.execute_input":"2024-05-05T15:27:30.324342Z","iopub.status.idle":"2024-05-05T15:27:36.100907Z","shell.execute_reply.started":"2024-05-05T15:27:30.324320Z","shell.execute_reply":"2024-05-05T15:27:36.099838Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/898 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec3d5d94ae0b449e92396d7accacdd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf0eefb755e54d718963e0e98ad37c5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c9028d387594793bcd08fa883571bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd53db272304f6489406b2a301fe417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/600M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"331feca5813f44faaa57c062f31099ae"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_rouge1_fmeasure_score_vlsp(preds, target):\n    rouge = Rouge()\n    scores = rouge.get_scores(preds, target, avg=False)\n    rouge1_fmeasure= scores[0]['rouge-1'][\"f\"]\n    rouge2_fmeasure= scores[0]['rouge-2'][\"f\"]\n    rougeL_fmeasure= scores[0]['rouge-l'][\"f\"]\n    return {\n        'rouge_1': rouge1_fmeasure,\n        'rouge_2': rouge2_fmeasure,\n        'rouge_L': rougeL_fmeasure,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.103186Z","iopub.execute_input":"2024-05-05T15:27:36.103506Z","iopub.status.idle":"2024-05-05T15:27:36.108953Z","shell.execute_reply.started":"2024-05-05T15:27:36.103461Z","shell.execute_reply":"2024-05-05T15:27:36.108016Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(sample):\n    # Tạo input cho mô hình từ câu hỏi và nội dung\n    inputs = sample[\"question\"] + \" \" + sample[\"context\"]\n    # Tạo nhãn cho mô hình từ câu trả lời\n    #labels = sample[\"answer\"]\n\n\n    # tokenize inputs\n    #model_inputs = tokenizer(inputs, max_length=1024, padding='max_length', truncation=True)\n    model_inputs = tokenizer(\n        sample[\"question\"],\n        sample[\"context\"],\n        max_length=1024,\n        truncation= \"only_second\",\n        stride=50,\n        padding = True\n        #return_overflowing_tokens=True,\n        #return_offsets_mapping=True,\n        )\n    # Tokenize targets with the `text_target` keyword argument\n    labels = tokenizer(text_target=sample[\"answer\"], max_length=1024, padding='max_length', truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n \n    return {\n        'input_ids': model_inputs['input_ids'],\n        'attention_mask': model_inputs['attention_mask'],\n        'labels': model_inputs['labels']\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.110107Z","iopub.execute_input":"2024-05-05T15:27:36.110388Z","iopub.status.idle":"2024-05-05T15:27:36.121396Z","shell.execute_reply.started":"2024-05-05T15:27:36.110366Z","shell.execute_reply":"2024-05-05T15:27:36.120428Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = compute_rouge1_fmeasure_score_vlsp(preds=decoded_preds, target=decoded_labels)\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result['gen_len'] = np.mean(prediction_lens)\n\n    return {\n        'rouge-1': result['rouge_1'],\n        'rouge_2': result['rouge_2'],\n        'rouge_L': result['rouge_L'],\n        'gen_len': result['gen_len'],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.122716Z","iopub.execute_input":"2024-05-05T15:27:36.123134Z","iopub.status.idle":"2024-05-05T15:27:36.130787Z","shell.execute_reply.started":"2024-05-05T15:27:36.123085Z","shell.execute_reply":"2024-05-05T15:27:36.130023Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nimport json\ndef merge_json_files(data1, data2):\n    merged_data = []\n    x = len(data2)//len(data1)\n    # Nối dữ liệu từ file 1 và file 2, chỉ giữ lại các trường \"question\", \"context\", và \"answer\"\n    i, j = 0, 0\n    while i < len(data1) and j < len(data2):\n        item = data1[i]\n        merged_item = {\n            \"question\": item[\"question\"],\n            \"context\": item[\"context\"],\n            \"answer\": item[\"answer\"]\n        }\n        merged_data.append(merged_item)\n        for _ in range(x):\n            if j < len(data2):\n                merged_data.append(data2[j])\n                j += 1\n        i += 1\n\n    # Nếu còn dữ liệu ở file 2, thêm vào cuối\n    while j < len(data2):\n        merged_data.append(data2[j])\n        j += 1\n\n    return merged_data","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.131717Z","iopub.execute_input":"2024-05-05T15:27:36.131985Z","iopub.status.idle":"2024-05-05T15:27:36.143288Z","shell.execute_reply.started":"2024-05-05T15:27:36.131949Z","shell.execute_reply":"2024-05-05T15:27:36.142488Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_json_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.144270Z","iopub.execute_input":"2024-05-05T15:27:36.144563Z","iopub.status.idle":"2024-05-05T15:27:36.151660Z","shell.execute_reply.started":"2024-05-05T15:27:36.144541Z","shell.execute_reply":"2024-05-05T15:27:36.150898Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Đọc dữ liệu từ file JSON\nnoanswer_data = load_json_file('/kaggle/input/yesno-qa/Law-QA-noanswer.json')\nlaw_qa = load_json_file('/kaggle/input/law-qa/Law-QA-train.json')\nvimqa_data = load_json_file('/kaggle/input/vimqa-dataset/train_vimqa.json')\nyesno_qa = load_json_file('/kaggle/input/yesno-qa/train_yesnoqa_translated.json')\ntrain_data0 = merge_json_files(noanswer_data, law_qa)\ntrain_data1 = merge_json_files(vimqa_data, train_data0)\ntrain_data = merge_json_files(yesno_qa, train_data1)\ntest_data = load_json_file('/kaggle/input/law-qa/Law-QA-test.json')\n\ncolumns = [\"question\", \"context\", \"answer\"]\n\n# Tạo danh sách dữ liệu của các cột\nlist_data_train = {column: [item[column] for item in train_data] for column in columns}\nlist_data_test = {column: [item[column] for item in test_data] for column in columns}\n# Tạo đối tượng Dataset từ danh sách dữ liệu\ntrain = Dataset.from_dict(list_data_train)\ntest = Dataset.from_dict(list_data_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:36.152644Z","iopub.execute_input":"2024-05-05T15:27:36.152905Z","iopub.status.idle":"2024-05-05T15:27:57.080191Z","shell.execute_reply.started":"2024-05-05T15:27:36.152884Z","shell.execute_reply":"2024-05-05T15:27:57.079420Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:57.082746Z","iopub.execute_input":"2024-05-05T15:27:57.083031Z","iopub.status.idle":"2024-05-05T15:27:57.089694Z","shell.execute_reply.started":"2024-05-05T15:27:57.083009Z","shell.execute_reply":"2024-05-05T15:27:57.088873Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'reference': ['https://thuvienphapluat.vn/van-ban/Tai-chinh-nha-nuoc/Thong-tu-58-2016-TT-BTC-su-dung-von-nha-nuoc-mua-sam-duy-tri-hoat-dong-thuong-xuyen-co-quan-nha-nuoc-308392.aspx?anchor=dieu_15'],\n 'context': 'Căn cứ Điều 3 Thông tư 58/2016/TT-BTC quy định về các hình thức lựa chọn nhà thầu như sau:\\n\"Điều 3. Các hình thức lựa chọn nhà thầu\\n1. Các hình thức lựa chọn nhà thầu bao gồm: đấu thầu rộng rãi, đấu thầu hạn chế, chỉ định thầu, mua sắm trực tiếp, chào hàng cạnh tranh, tự thực hiện và lựa chọn nhà thầu trong trường hợp đặc biệt.\\n2. Căn cứ dự toán chi ngân sách hàng năm, dự toán bổ sung trong năm được cơ quan có thẩm quyền giao và Quyết định mua sắm tài sản của cấp có thẩm quyền quy định tại Khoản 1 Điều 5 Thông tư này, Thủ trưởng cơ quan, đơn vị áp dụng hình thức lựa chọn nhà thầu để tổ chức thực hiện mua sắm hàng hóa, dịch vụ theo đúng quy định.\\n3. Đối với các gói thầu mua sắm tài sản, hàng hóa, dịch vụ đủ Điều kiện để áp dụng các hình thức mua sắm không phải đấu thầu; nếu cơ quan, đơn vị thấy cần thiết phải tổ chức đấu thầu để bảo đảm Mục tiêu quản lý và sử dụng có hiệu quả ngân sách nhà nước thì tổ chức thực hiện đấu thầu rộng rãi theo quy định và báo cáo cấp có thẩm quyền về kết quả mua sắm tài sản, hàng hóa, dịch vụ.\"\\nChọn nhà thầu \\nTheo Điều 15 Thông tư 58/2016/TT-BTC quy định các trường hợp được phép chỉ định gói thầu như sau:\\n\"Điều 15. Các trường hợp được áp dụng chỉ định thầu\\n1. Các gói thầu quy định tại Khoản 1 Điều 22 Luật Đấu thầu, gồm:\\na) Gói thầu cần thực hiện để khắc phục ngay hoặc để xử lý kịp thời hậu quả gây ra do sự cố bất khả kháng; gói thầu cần thực hiện để bảo đảm bí mật nhà nước; gói thầu cần triển khai ngay để tránh gây nguy hại trực tiếp đến tính mạng, sức khỏe và tài sản của cộng đồng dân cư trên địa bàn hoặc để không ảnh hưởng nghiêm trọng đến công trình liền kề; gói thầu mua hóa chất, vật tư, thiết bị y tế để triển khai công tác phòng, chống dịch bệnh trong trường hợp cấp bách;\\nb) Gói thầu cấp bách cần triển khai nhằm Mục tiêu bảo vệ chủ quyền quốc gia, biên giới quốc gia, hải đảo;\\nc) Gói thầu cung cấp dịch vụ tư vấn, dịch vụ phi tư vấn, mua sắm hàng hóa phải mua từ nhà thầu đã thực hiện trước đó do phải bảo đảm tính tương thích về công nghệ, bản quyền mà không thể mua được từ nhà thầu khác; gói thầu có tính chất nghiên cứu, thử nghiệm; mua bản quyền sở hữu trí tuệ;\\nd) Gói thầu cung cấp dịch vụ tư vấn lập báo cáo nghiên cứu khả thi, thiết kế xây dựng được chỉ định cho tác giả của thiết kế kiến trúc công trình trúng tuyển hoặc được tuyển chọn khi tác giả có đủ Điều kiện năng lực theo quy định; gói thầu thi công xây dựng tượng đài, phù điêu, tranh hoành tráng, tác phẩm nghệ thuật gắn với quyền tác giả từ khâu sáng tác đến thi công công trình.\\n2. Gói thầu mua sắm tài sản, hàng hóa, dịch vụ thuộc đề án hoặc dự toán mua sắm thường xuyên có giá gói thầu không quá 100.000.000 đồng (một trăm triệu đồng).\\n3. Việc thực hiện chỉ định thầu đối với gói thầu quy định tại Điểm b, c, d Khoản 1 và Khoản 2 Điều này phải đáp ứng đủ các Điều kiện sau đây:\\na) Có kế hoạch lựa chọn nhà thầu được phê duyệt;\\nb) Có thời gian thực hiện chỉ định thầu kể từ ngày phê duyệt hồ sơ yêu cầu đến ngày ký kết hợp đồng không quá 45 ngày; trường hợp gói thầu có quy mô lớn, phức tạp không quá 90 ngày;\\nc) Nhà thầu được đề nghị chỉ định thầu phải có tên trong cơ sở dữ liệu về nhà thầu theo quy định của Bộ Kế hoạch và Đầu tư (trừ gói thầu quy định tại Khoản 2 Điều này).\" \\nCăn cứ Điều 54 Nghị định 63/2014/NĐ-CP hướng dẫn Luật Đấu thầu 2013 quy định về hạn mức chỉ định đấu thầu như sau:\\n\"Điều 54. Hạn mức chỉ định thầu\\nGói thầu có giá trị trong hạn mức được áp dụng chỉ định thầu theo quy định tại Điểm e Khoản 1 Điều 22 của Luật Đấu thầu bao gồm:\\n1. Không quá 500 triệu đồng đối với gói thầu cung cấp dịch vụ tư vấn, dịch vụ phi tư vấn, dịch vụ công; không quá 01 tỷ đồng đối với gói thầu mua sắm hàng hóa, xây lắp, hỗn hợp, mua thuốc, vật tư y tế, sản phẩm công;\\n2. Không quá 100 triệu đồng đối với gói thầu thuộc dự toán mua sắm thường xuyên.\"',\n 'answer': 'Tại khoản 2 Điều này quy định gói thầu mua sắm tài sản, hàng hóa, dịch vụ thuộc đề án hoặc dự toán mua sắm thường xuyên có giá gói thầu không quá 100.000.000 đồng (một trăm triệu đồng). Trường hợp gói thầu đầu tư ứng dụng công nghệ thông tin của  đã quá 100 triệu đồng nên không thể áp dụng chị định gói thầu theo Thông tư 58/2016/TT-BTC được',\n 'question': 'Gói thầu tư vấn có giá trị 122 triệu đồng thuộc dự án đầu tư ứng dụng công nghệ thông tin sử dụng nguồn vốn chi thường xuyên có được áp dụng chỉ định thầu theo Thông tư 58/2016/TT-BTC không?',\n 'domain': ['Tài chính nhà nước']}"},"metadata":{}}]},{"cell_type":"code","source":"def train_test_splits():\n    train_data = (train.map(preprocess_function, remove_columns=['question', 'context', 'answer']))\n    test_data = (test.map(preprocess_function, remove_columns=['question', 'context', 'answer']))\n    return train_data, test_data\n\nprint('------------------------------------------------Loading Data----------------------------------------------------')\ntrain_data, test_data = train_test_splits()\nprint('----------------------------------------------------Done!-------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:27:57.090885Z","iopub.execute_input":"2024-05-05T15:27:57.091160Z","iopub.status.idle":"2024-05-05T15:43:18.846692Z","shell.execute_reply.started":"2024-05-05T15:27:57.091139Z","shell.execute_reply":"2024-05-05T15:43:18.845717Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"------------------------------------------------Loading Data----------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/178178 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea052f79a4de43dea2effb952220f1a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2898 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6145e69c775d447aa33ac3b9945ac95f"}},"metadata":{}},{"name":"stdout","text":"----------------------------------------------------Done!-------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Subset\nsubset_size = 144000\nsuset_size = 300\nsubset_train_data = Subset(train_data, range(subset_size))\nsubset_valid_data = Subset(test_data, range(suset_size))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:43:18.847925Z","iopub.execute_input":"2024-05-05T15:43:18.848210Z","iopub.status.idle":"2024-05-05T15:43:18.853115Z","shell.execute_reply.started":"2024-05-05T15:43:18.848186Z","shell.execute_reply":"2024-05-05T15:43:18.852126Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    pad_to_multiple_of=8,\n    #padding = True\n)\n\ntraining_args =Seq2SeqTrainingArguments(\n    output_dir=\"./Checkpoint Bartpho\",\n    gradient_checkpointing=True,\n    do_train=True,\n    remove_unused_columns=False,\n    warmup_ratio=0.05,\n    weight_decay=0.01,\n    group_by_length=True,\n    fp16=True,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    predict_with_generate=True,\n    learning_rate=2e-5,\n    num_train_epochs=1,\n    logging_strategy=\"steps\",\n    logging_steps=3000,\n    save_steps=3000,\n    eval_steps=3000,\n    evaluation_strategy=\"steps\",\n    save_total_limit=5,\n)\n\n\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    eval_dataset=test_data,\n    train_dataset=subset_train_data,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# tokenizer.save_pretrained('./Checkpoint Bartpho/Final/Tokenizer-Pipeline')\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:43:18.854147Z","iopub.execute_input":"2024-05-05T15:43:18.854396Z","iopub.status.idle":"2024-05-06T01:51:31.625033Z","shell.execute_reply.started":"2024-05-05T15:43:18.854375Z","shell.execute_reply":"2024-05-06T01:51:31.624034Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240505_154808-qv69ltu6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nguyenbatuan/huggingface/runs/qv69ltu6' target=\"_blank\">clone-shuttle-42</a></strong> to <a href='https://wandb.ai/nguyenbatuan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nguyenbatuan/huggingface' target=\"_blank\">https://wandb.ai/nguyenbatuan/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nguyenbatuan/huggingface/runs/qv69ltu6' target=\"_blank\">https://wandb.ai/nguyenbatuan/huggingface/runs/qv69ltu6</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9000/9000 10:02:45, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge-1</th>\n      <th>Rouge 2</th>\n      <th>Rouge L</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>3000</td>\n      <td>0.366200</td>\n      <td>0.118206</td>\n      <td>0.333333</td>\n      <td>0.121951</td>\n      <td>0.166667</td>\n      <td>19.902692</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.114900</td>\n      <td>0.100942</td>\n      <td>0.333333</td>\n      <td>0.121951</td>\n      <td>0.166667</td>\n      <td>19.902346</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.104300</td>\n      <td>0.095158</td>\n      <td>0.333333</td>\n      <td>0.121951</td>\n      <td>0.166667</td>\n      <td>19.886128</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=9000, training_loss=0.19511480034722223, metrics={'train_runtime': 36245.3483, 'train_samples_per_second': 3.973, 'train_steps_per_second': 0.248, 'total_flos': 6.58781757383639e+16, 'train_loss': 0.19511480034722223, 'epoch': 1.0})"},"metadata":{}}]}]}